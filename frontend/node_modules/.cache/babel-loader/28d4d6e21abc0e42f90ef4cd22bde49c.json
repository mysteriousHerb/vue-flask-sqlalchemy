{"remainingRequest":"C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\node_modules\\babel-loader\\lib\\index.js!C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\node_modules\\cache-loader\\dist\\cjs.js??ref--0-0!C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\node_modules\\vue-loader\\lib\\index.js??vue-loader-options!C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\src\\components\\FaceDetection.vue?vue&type=script&lang=js&","dependencies":[{"path":"C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\src\\components\\FaceDetection.vue","mtime":1561411722829},{"path":"C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\node_modules\\cache-loader\\dist\\cjs.js","mtime":1560457563834},{"path":"C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\node_modules\\babel-loader\\lib\\index.js","mtime":1560457563473},{"path":"C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\node_modules\\cache-loader\\dist\\cjs.js","mtime":1560457563834},{"path":"C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\node_modules\\vue-loader\\lib\\index.js","mtime":1560457580480}],"contextDependencies":[],"result":["import \"core-js/modules/es7.object.values\";\nimport \"core-js/modules/es6.object.keys\";\nimport \"core-js/modules/es6.regexp.match\";\nimport \"regenerator-runtime/runtime\";\nimport _asyncToGenerator from \"C:\\\\Users\\\\My Pc\\\\Documents\\\\GitHub\\\\vue-flask-sqlalchemy\\\\frontend\\\\node_modules\\\\@babel\\\\runtime-corejs2/helpers/esm/asyncToGenerator\";\nimport \"core-js/modules/web.dom.iterable\";\nimport \"core-js/modules/es6.string.iterator\";\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n// useful tutorial: https://www.youtube.com/watch?v=CVClHLwv-4I&feature=youtu.be\n// https://github.com/WebDevSimplified/Face-Detection-JavaScript/blob/master/script.js\nimport * as faceapi from \"face-api.js\";\nimport { async } from \"q\";\nimport { setTimeout, setInterval } from \"timers\";\nimport FileSaver from \"file-saver\";\nimport Icon from \"vue-awesome/components/Icon\";\nimport vue2Dropzone from \"vue2-dropzone\";\nimport \"vue2-dropzone/dist/vue2Dropzone.min.css\";\nexport default {\n  name: \"FaceDetection\",\n  components: {\n    \"v-fa-icon\": Icon,\n    vueDropzone: vue2Dropzone\n  },\n  data: function data() {\n    return {\n      display_size: {\n        width: 640,\n        height: 480\n      },\n      detections: [],\n      temp_detections: [],\n      capture_file_count: 0,\n      detected: false,\n      resizedDetections: [],\n      confirmed_user: \"\",\n      refresh_time: 50,\n      // determine sensitivity for left and right face, higher = more turning needed\n      left_right_turning_ratio: 2,\n      // determine sensitivity for look up, higher = more turning needed\n      up_slope_threshold: -0.1,\n      down_slope_threshold: -0.55,\n      // larger the more opening\n      mouth_threshold: 0.7,\n      // larger the more opening\n      eyebrow_threshold: 1.0,\n      // List of available instructions\n      instructions: [{\n        command: \"Turn Left!\",\n        icon: \"arrow-alt-circle-left\"\n      }, {\n        command: \"Turn Right!\",\n        icon: \"arrow-alt-circle-right\"\n      }, {\n        command: \"Look Up!\",\n        icon: \"arrow-alt-circle-up\"\n      }, {\n        command: \"Look Down!\",\n        icon: \"arrow-alt-circle-down\"\n      }, {\n        command: \"Smile!\",\n        icon: \"laugh\"\n      }, {\n        command: \"Open mouth!\",\n        icon: \"teeth-open\" // \"Raise eyebrows!\"\n\n      }],\n      current_instruction: {\n        command: \"\",\n        icon: \"\"\n      },\n      liveness_detection_status: {\n        left_right_status: \"neutral\",\n        up_down_status: \"neutral\",\n        expression: \"neutral\",\n        mouth: \"neutral\",\n        eyebrow: \"neutral\"\n      },\n      liveness_test_instructions: []\n    };\n  },\n  watch: {\n    temp_detections: function temp_detections(new_val, old_val) {\n      console.log(new_val);\n    }\n  },\n  mounted: function mounted() {\n    this.load_faceapi_models();\n    this.start_video();\n    this.generate_liveness_test();\n  },\n  computed: {\n    session_id: function session_id() {\n      // session_id should be sent to all the axios request to backend now\n      return this.$store.state.session_id;\n    },\n    user_name_in_key: function user_name_in_key() {\n      return this.$store.state.user_name_in_key;\n    }\n  },\n  methods: {\n    generate_liveness_test: function generate_liveness_test() {\n      // DEBUG: add a timer for each test?\n      function shuffleArray(array) {\n        for (var i = array.length - 1; i > 0; i--) {\n          var j = Math.floor(Math.random() * (i + 1));\n          var _ref = [array[j], array[i]];\n          array[i] = _ref[0];\n          array[j] = _ref[1];\n        }\n      }\n\n      if (this.instructions.length == 0) {\n        console.log(\"you are a human!\");\n        this.current_instruction.command = \"\";\n        this.match_known_descriptor();\n      } else {\n        shuffleArray(this.instructions);\n        this.current_instruction = this.instructions[0];\n      }\n    },\n    liveness_test: function liveness_test() {\n      var test = this.current_instruction.command;\n      var result = this.liveness_detection_status; // use the neutral pose to ensure we don't get false detection\n\n      var neutral_l_r_pose = result.left_right_status == \"neutral\";\n      var neutral_u_d_pose = result.up_down_status == \"neutral\";\n      var neutral_mouth = result.mouth == \"neutral\";\n\n      if (test == \"Turn Left!\" && result.left_right_status == \"left\") {\n        this.generate_face_descriptor();\n        return true;\n      } else if (test == \"Turn Right!\" && result.left_right_status == \"right\") {\n        this.generate_face_descriptor();\n        return true;\n      } else if (test == \"Look Up!\" && result.up_down_status == \"up\" && neutral_l_r_pose && neutral_mouth) {\n        this.generate_face_descriptor();\n        return true;\n      } else if (test == \"Look Down!\" && result.up_down_status == \"down\" && neutral_l_r_pose && neutral_mouth) {\n        this.generate_face_descriptor();\n        return true;\n      } else if (test == \"Smile!\" && result.expression == \"happy\" && neutral_l_r_pose && neutral_u_d_pose) {\n        this.generate_face_descriptor();\n        return true;\n      } else if (test == \"Open mouth!\" && result.mouth == \"open\" && neutral_l_r_pose) {\n        this.generate_face_descriptor();\n        return true;\n      } // } else if (\n      //   test == \"Raise eyebrows!\" &&\n      //   result.eyebrow == \"raised\" &&\n      //   neutral_l_r_pose &&\n      //   neutral_u_d_pose\n      // ) {\n      //   return true;\n      // }\n\n    },\n    load_faceapi_models: function load_faceapi_models() {\n      // save the models to the public/models\n      // faceapi.nets.ssdMobilenetv1.loadFromUri(\"/models\"),\n      Promise.all([faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\"), faceapi.nets.faceLandmark68Net.loadFromUri(\"/models\"), faceapi.nets.faceRecognitionNet.loadFromUri(\"/models\"), faceapi.nets.faceExpressionNet.loadFromUri(\"/models\")]).then(console.log(\"model loaded\"));\n    },\n    start_video: function start_video() {\n      navigator.getUserMedia({\n        video: {}\n      }, function (stream) {\n        return video.srcObject = stream;\n      }, function (err) {\n        return console.error(err);\n      });\n    },\n    generate_face_descriptor: function generate_face_descriptor() {\n      // https://x-team.com/blog/webcam-capture-vue/\n      var self = this;\n\n      if (self.detections) {\n        // keep track how many images we have captured\n        self.capture_file_count += 1; // console.log(this.detections);\n        // console.log(self.capture_file_count);\n\n        var canvas = self.$refs.canvas_capture;\n        var context = canvas.getContext(\"2d\");\n        context.clearRect(0, 0, canvas.width, canvas.height);\n        var box = self.detections.detection.box; // Sending the face with cropped region \n        // drawImage from the video stream, with cropping\n\n        context.drawImage(self.$refs.video, box.x, box.y, box.width, box.height, box.x, box.y, box.width, box.height); // // sending the whole image \n        //   context.drawImage(\n        //   self.$refs.video,\n        //   0, 0, self.display_size['width'], self.display_size['height']\n        // );\n        // // // sending the face_location to backend to save some repetition \n        // // // top, right, bottom, left\n\n        var face_location = [box.top, box.right, box.bottom, box.left]; // Saving canvas to local drive is easy: https://github.com/eligrey/FileSaver.js/\n\n        self.$refs.canvas_capture.toBlob(\n        /*#__PURE__*/\n        function () {\n          var _ref2 = _asyncToGenerator(\n          /*#__PURE__*/\n          regeneratorRuntime.mark(function _callee(blob) {\n            var formData;\n            return regeneratorRuntime.wrap(function _callee$(_context) {\n              while (1) {\n                switch (_context.prev = _context.next) {\n                  case 0:\n                    // result = await faceapi.bufferToImage(blob).\n                    // upload Blob as a form to the flask backend and generate descriptors\n                    // https://github.com/pagekit/vue-resource/blob/master/docs/recipes.md\n                    formData = new FormData(); // formData.append(name, value, filename);\n\n                    formData.append(\"file\", blob, \"unknown_face_\" + self.capture_file_count + \".jpg\");\n                    formData.append(\"session_id\", self.session_id);\n                    formData.append(\"face_location\", face_location);\n                    self.axios({\n                      url: self.$API_URL + \"/generate_descriptor\",\n                      method: \"POST\",\n                      data: formData\n                    });\n\n                  case 5:\n                  case \"end\":\n                    return _context.stop();\n                }\n              }\n            }, _callee);\n          }));\n\n          return function (_x) {\n            return _ref2.apply(this, arguments);\n          };\n        }());\n      }\n    },\n    match_known_descriptor: function match_known_descriptor() {\n      var _this = this;\n\n      this.axios({\n        url: this.$API_URL + \"/compare_descriptors\",\n        method: \"POST\",\n        data: {\n          session_id: this.session_id\n        }\n      }).then(function (response) {\n        if (response.data.match) {\n          _this.confirmed_user = response.data.user;\n        }\n      });\n    },\n    show_capture: function show_capture() {\n      console.log(this.temp_detections);\n    },\n    detect_and_draw_faces: function detect_and_draw_faces() {\n      console.log(\"start detecting faces\"); // https://michaelnthiessen.com/this-is-undefined/\n      // https://stackoverflow.com/questions/47148363/when-to-use-vm-or-this-in-vue-js\n      // arrow function is a pain in vue.js and this async function also seems to cause problem\n\n      var self = this;\n      setInterval(\n      /*#__PURE__*/\n      _asyncToGenerator(\n      /*#__PURE__*/\n      regeneratorRuntime.mark(function _callee2() {\n        var resizedDetections, message2, message;\n        return regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                _context2.next = 2;\n                return faceapi.detectSingleFace(self.$refs.video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n\n              case 2:\n                self.detections = _context2.sent;\n\n                // calculating the 128 descriptors seems to be rather slow, lets not do it very frequent or do it in backend\n                // .withFaceDescriptors();\n                if (self.detections) {\n                  self.detected = true; // calculated the size that is on our canvas size\n\n                  resizedDetections = faceapi.resizeResults(self.detections, self.display_size); // replace the result with scaled one, all the other information will remain\n\n                  self.detections = resizedDetections; // call other methods\n\n                  self.mouth_eye_status();\n                  self.head_pose_estimation();\n                  self.find_expression(); // annotation\n\n                  message2 = [\"L/R: \" + self.liveness_detection_status.left_right_status, \"U/D: \" + self.liveness_detection_status.up_down_status, \"Expression: \" + self.liveness_detection_status.expression, \"mouth: \" + self.liveness_detection_status.mouth, \"eyebrow: \" + self.liveness_detection_status.eyebrow];\n                  message = \"Hello\"; // only append the username after liveness test\n\n                  if (self.instructions.length == 0 && self.confirmed_user != \"\") {\n                    message = \"Hello: \" + self.user_name_in_key + \"!\";\n                  } else if (self.instructions.length == 0 && self.confirmed_user == \"\") {\n                    message = \"Hello: Stranger! Maybe you are not who you claim to be\";\n                  }\n\n                  self.annotation({\n                    clear: false,\n                    message: message,\n                    message2: message2\n                  }); // liveness test is passed, we move on with next test\n\n                  if (self.instructions.length != 0) {\n                    if (self.liveness_test()) {\n                      self.instructions.shift();\n                      self.generate_liveness_test();\n                    }\n                  }\n                } else {\n                  self.annotation({\n                    clear: true\n                  });\n                }\n\n              case 4:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2);\n      })), self.refresh_time);\n    },\n    // note how to use named arguments in javascript...\n    annotation: function annotation(_ref4) {\n      var _ref4$clear = _ref4.clear,\n          clear = _ref4$clear === void 0 ? false : _ref4$clear,\n          _ref4$message = _ref4.message,\n          message = _ref4$message === void 0 ? \"Hello!\" : _ref4$message,\n          _ref4$message2 = _ref4.message2,\n          message2 = _ref4$message2 === void 0 ? [] : _ref4$message2;\n      var canvas = this.$refs.canvas;\n      var canvas_flip = this.$refs.canvas_flip; // clear canvas before drawing the new things to prevent cluttering\n\n      canvas.getContext(\"2d\").clearRect(0, 0, canvas.width, canvas.height);\n      canvas_flip.getContext(\"2d\").clearRect(0, 0, canvas_flip.width, canvas_flip.height); // set to clear when no face can be found\n\n      if (clear === false) {\n        // NOTE: There are some useful drawing functions already exist\n        faceapi.draw.drawFaceLandmarks(canvas_flip, this.detections); // Draw box around the face with 1 line text\n\n        var box = this.detections.detection.box; // mirror X\n\n        var box_X_flipped = {\n          x: canvas.width - box.x - box.width,\n          y: box.y,\n          width: box.width,\n          height: box.height\n        }; // see DrawBoxOptions below\n\n        var boxOptions = {\n          label: message,\n          lineWidth: 2,\n          boxColor: \"rgba(57,255,20,0.8)\"\n        }; // flip the x-value x, y, width, height\n\n        var drawBox = new faceapi.draw.DrawBox(box_X_flipped, boxOptions);\n        drawBox.draw(canvas); // ------- multi-line text at bottom -------\n\n        if (message2.length != 0) {\n          var text = message2;\n          var anchor = this.detections.detection.box.bottomLeft;\n          var anchor_X_flipped = {\n            x: canvas.width - anchor.x - box.width,\n            y: anchor.y\n          }; // see DrawTextField below\n\n          var textOptions = {\n            anchorPosition: \"TOP_LEFT\",\n            backgroundColor: \"rgba(57,255,20, 0.5)\"\n          };\n          var drawText = new faceapi.draw.DrawTextField(text, anchor_X_flipped, textOptions);\n          drawText.draw(canvas);\n        }\n      }\n    },\n    find_expression: function find_expression() {\n      var expressions = this.detections.expressions; // find the max value of all the keys\n      // The reducer function takes four arguments: Accumulator (acc), Current Value (cur), Current Index (idx)\n      // the question mark is conditional operator, which returns true_val:false_val\n\n      var likely_expression = Object.keys(expressions).reduce(function (i, j) {\n        return expressions[i] > expressions[j] ? i : j;\n      });\n      var expression_possibility = expressions[likely_expression];\n      this.liveness_detection_status[\"expression\"] = likely_expression;\n      return likely_expression + \":\" + String(expression_possibility);\n    },\n    head_pose_estimation: function head_pose_estimation() {\n      var landmarks = this.detections.landmarks;\n      var landmarkPositions = landmarks.positions; // the distance between 1 and 28 will be shorter when extending left face\n\n      var right_face_distance = faceapi.euclideanDistance(Object.values(landmarkPositions[16]), Object.values(landmarkPositions[28]));\n      var left_face_distance = faceapi.euclideanDistance(Object.values(landmarkPositions[0]), Object.values(landmarkPositions[28]));\n      var right_to_left_face_ratio = right_face_distance / left_face_distance; // the point 6 - 12 become more flat when facing upward. calculate the slope\n\n      var chin_slope_left = (landmarkPositions[5].y - landmarkPositions[8].y) / (landmarkPositions[8].x - landmarkPositions[5].x);\n      var chin_slope_right = (landmarkPositions[11].y - landmarkPositions[8].y) / (landmarkPositions[11].x - landmarkPositions[8].x);\n      var chin_slope_average = (chin_slope_left + chin_slope_right) / 2; // NOTE: make this vue variable\n\n      if (right_to_left_face_ratio > 1 / this.left_right_turning_ratio && right_to_left_face_ratio < this.left_right_turning_ratio) {\n        this.liveness_detection_status[\"left_right_status\"] = \"neutral\";\n      } else if (right_to_left_face_ratio > this.left_right_turning_ratio) {\n        this.liveness_detection_status[\"left_right_status\"] = \"right\";\n      } else if (right_to_left_face_ratio < 1 / this.left_right_turning_ratio) {\n        this.liveness_detection_status[\"left_right_status\"] = \"left\";\n      }\n\n      if (chin_slope_average > this.up_slope_threshold) {\n        this.liveness_detection_status[\"up_down_status\"] = \"up\";\n      } else if (chin_slope_average < this.down_slope_threshold) {\n        this.liveness_detection_status[\"up_down_status\"] = \"down\";\n      } else {\n        this.liveness_detection_status[\"up_down_status\"] = \"neutral\";\n      }\n    },\n    mouth_eye_status: function mouth_eye_status() {\n      //  https://towardsdatascience.com/mouse-control-facial-movements-hci-app-c16b0494a971\n      var landmarks = this.detections.landmarks;\n      var landmarkPositions = landmarks.positions; // https://www.pyimagesearch.com/2017/04/24/eye-blink-detection-opencv-python-dlib/\n\n      var mouth_y = faceapi.euclideanDistance(Object.values(landmarkPositions[51]), Object.values(landmarkPositions[57]));\n      var mouth_x = faceapi.euclideanDistance(Object.values(landmarkPositions[54]), Object.values(landmarkPositions[48]));\n      var mouth_aspect_ratio = mouth_y / mouth_x;\n\n      if (mouth_aspect_ratio > this.mouth_threshold) {\n        this.liveness_detection_status.mouth = \"open\";\n      } else {\n        this.liveness_detection_status.mouth = \"neutral\";\n      } //  ------------- eyebrow measurment: use the distance between eyebrow and eye vs\n      // the width of the eyes (rather constant)  to test whether the eyebrows are raised\n\n\n      var l_eyebrow_eye_d = faceapi.euclideanDistance(Object.values(landmarkPositions[19]), Object.values(landmarkPositions[37]));\n      var r_eyebrow_eye_d = faceapi.euclideanDistance(Object.values(landmarkPositions[24]), Object.values(landmarkPositions[44])); // use eyebrow as a reference point\n\n      var l_eye_w = faceapi.euclideanDistance(Object.values(landmarkPositions[39]), Object.values(landmarkPositions[36]));\n      var r_eye_w = faceapi.euclideanDistance(Object.values(landmarkPositions[42]), Object.values(landmarkPositions[45]));\n      var eyebrow_d_eye_w_ratio = (l_eyebrow_eye_d + r_eyebrow_eye_d) / (l_eye_w + r_eye_w);\n\n      if (eyebrow_d_eye_w_ratio > this.eyebrow_threshold) {\n        this.liveness_detection_status.eyebrow = \"raised\";\n      } else {\n        this.liveness_detection_status.eyebrow = \"neutral\";\n      }\n    },\n    download_face_descriptor: function download_face_descriptor() {\n      console.log(this.detections);\n      var detections_json = JSON.stringify(this.detections);\n      var blob = new Blob([detections_json], {\n        type: \"application/json\"\n      });\n      FileSaver.saveAs(blob, \"key.json\");\n    }\n  }\n};",{"version":3,"sources":["FaceDetection.vue"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAwDA;AACA;AAEA,OAAA,KAAA,OAAA,MAAA,aAAA;AACA,SAAA,KAAA,QAAA,GAAA;AACA,SAAA,UAAA,EAAA,WAAA,QAAA,QAAA;AACA,OAAA,SAAA,MAAA,YAAA;AACA,OAAA,IAAA,MAAA,6BAAA;AACA,OAAA,YAAA,MAAA,eAAA;AACA,OAAA,yCAAA;AAEA,eAAA;AACA,EAAA,IAAA,EAAA,eADA;AAEA,EAAA,UAAA,EAAA;AACA,iBAAA,IADA;AAEA,IAAA,WAAA,EAAA;AAFA,GAFA;AAMA,EAAA,IAAA,EAAA,gBAAA;AACA,WAAA;AACA,MAAA,YAAA,EAAA;AAAA,QAAA,KAAA,EAAA,GAAA;AAAA,QAAA,MAAA,EAAA;AAAA,OADA;AAEA,MAAA,UAAA,EAAA,EAFA;AAGA,MAAA,eAAA,EAAA,EAHA;AAIA,MAAA,kBAAA,EAAA,CAJA;AAKA,MAAA,QAAA,EAAA,KALA;AAMA,MAAA,iBAAA,EAAA,EANA;AAOA,MAAA,cAAA,EAAA,EAPA;AAQA,MAAA,YAAA,EAAA,EARA;AASA;AACA,MAAA,wBAAA,EAAA,CAVA;AAWA;AACA,MAAA,kBAAA,EAAA,CAAA,GAZA;AAaA,MAAA,oBAAA,EAAA,CAAA,IAbA;AAcA;AACA,MAAA,eAAA,EAAA,GAfA;AAgBA;AACA,MAAA,iBAAA,EAAA,GAjBA;AAkBA;AACA,MAAA,YAAA,EAAA,CACA;AAAA,QAAA,OAAA,EAAA,YAAA;AAAA,QAAA,IAAA,EAAA;AAAA,OADA,EAEA;AAAA,QAAA,OAAA,EAAA,aAAA;AAAA,QAAA,IAAA,EAAA;AAAA,OAFA,EAGA;AAAA,QAAA,OAAA,EAAA,UAAA;AAAA,QAAA,IAAA,EAAA;AAAA,OAHA,EAIA;AAAA,QAAA,OAAA,EAAA,YAAA;AAAA,QAAA,IAAA,EAAA;AAAA,OAJA,EAKA;AAAA,QAAA,OAAA,EAAA,QAAA;AAAA,QAAA,IAAA,EAAA;AAAA,OALA,EAMA;AAAA,QAAA,OAAA,EAAA,aAAA;AAAA,QAAA,IAAA,EAAA,YAAA,CAEA;;AAFA,OANA,CAnBA;AA6BA,MAAA,mBAAA,EAAA;AAAA,QAAA,OAAA,EAAA,EAAA;AAAA,QAAA,IAAA,EAAA;AAAA,OA7BA;AA8BA,MAAA,yBAAA,EAAA;AACA,QAAA,iBAAA,EAAA,SADA;AAEA,QAAA,cAAA,EAAA,SAFA;AAGA,QAAA,UAAA,EAAA,SAHA;AAIA,QAAA,KAAA,EAAA,SAJA;AAKA,QAAA,OAAA,EAAA;AALA,OA9BA;AAqCA,MAAA,0BAAA,EAAA;AArCA,KAAA;AAuCA,GA9CA;AA+CA,EAAA,KAAA,EAAA;AACA,IAAA,eAAA,EAAA,yBAAA,OAAA,EAAA,OAAA,EAAA;AACA,MAAA,OAAA,CAAA,GAAA,CAAA,OAAA;AACA;AAHA,GA/CA;AAoDA,EAAA,OAAA,EAAA,mBAAA;AACA,SAAA,mBAAA;AACA,SAAA,WAAA;AACA,SAAA,sBAAA;AACA,GAxDA;AAyDA,EAAA,QAAA,EAAA;AACA,IAAA,UADA,wBACA;AACA;AACA,aAAA,KAAA,MAAA,CAAA,KAAA,CAAA,UAAA;AACA,KAJA;AAKA,IAAA,gBALA,8BAKA;AACA,aAAA,KAAA,MAAA,CAAA,KAAA,CAAA,gBAAA;AACA;AAPA,GAzDA;AAkEA,EAAA,OAAA,EAAA;AACA,IAAA,sBAAA,EAAA,kCAAA;AACA;AACA,eAAA,YAAA,CAAA,KAAA,EAAA;AACA,aAAA,IAAA,CAAA,GAAA,KAAA,CAAA,MAAA,GAAA,CAAA,EAAA,CAAA,GAAA,CAAA,EAAA,CAAA,EAAA,EAAA;AACA,cAAA,CAAA,GAAA,IAAA,CAAA,KAAA,CAAA,IAAA,CAAA,MAAA,MAAA,CAAA,GAAA,CAAA,CAAA,CAAA;AADA,qBAEA,CAAA,KAAA,CAAA,CAAA,CAAA,EAAA,KAAA,CAAA,CAAA,CAAA,CAFA;AAEA,UAAA,KAAA,CAAA,CAAA,CAFA;AAEA,UAAA,KAAA,CAAA,CAAA,CAFA;AAGA;AACA;;AACA,UAAA,KAAA,YAAA,CAAA,MAAA,IAAA,CAAA,EAAA;AACA,QAAA,OAAA,CAAA,GAAA,CAAA,kBAAA;AACA,aAAA,mBAAA,CAAA,OAAA,GAAA,EAAA;AACA,aAAA,sBAAA;AACA,OAJA,MAIA;AACA,QAAA,YAAA,CAAA,KAAA,YAAA,CAAA;AACA,aAAA,mBAAA,GAAA,KAAA,YAAA,CAAA,CAAA,CAAA;AACA;AACA,KAjBA;AAkBA,IAAA,aAAA,EAAA,yBAAA;AACA,UAAA,IAAA,GAAA,KAAA,mBAAA,CAAA,OAAA;AACA,UAAA,MAAA,GAAA,KAAA,yBAAA,CAFA,CAGA;;AACA,UAAA,gBAAA,GAAA,MAAA,CAAA,iBAAA,IAAA,SAAA;AACA,UAAA,gBAAA,GAAA,MAAA,CAAA,cAAA,IAAA,SAAA;AACA,UAAA,aAAA,GAAA,MAAA,CAAA,KAAA,IAAA,SAAA;;AAEA,UAAA,IAAA,IAAA,YAAA,IAAA,MAAA,CAAA,iBAAA,IAAA,MAAA,EAAA;AACA,aAAA,wBAAA;AACA,eAAA,IAAA;AACA,OAHA,MAGA,IAAA,IAAA,IAAA,aAAA,IAAA,MAAA,CAAA,iBAAA,IAAA,OAAA,EAAA;AACA,aAAA,wBAAA;AACA,eAAA,IAAA;AACA,OAHA,MAGA,IACA,IAAA,IAAA,UAAA,IACA,MAAA,CAAA,cAAA,IAAA,IADA,IAEA,gBAFA,IAGA,aAJA,EAKA;AACA,aAAA,wBAAA;AACA,eAAA,IAAA;AACA,OARA,MAQA,IACA,IAAA,IAAA,YAAA,IACA,MAAA,CAAA,cAAA,IAAA,MADA,IAEA,gBAFA,IAGA,aAJA,EAKA;AACA,aAAA,wBAAA;AACA,eAAA,IAAA;AACA,OARA,MAQA,IACA,IAAA,IAAA,QAAA,IACA,MAAA,CAAA,UAAA,IAAA,OADA,IAEA,gBAFA,IAGA,gBAJA,EAKA;AACA,aAAA,wBAAA;AACA,eAAA,IAAA;AACA,OARA,MAQA,IACA,IAAA,IAAA,aAAA,IACA,MAAA,CAAA,KAAA,IAAA,MADA,IAEA,gBAHA,EAIA;AACA,aAAA,wBAAA;AACA,eAAA,IAAA;AACA,OA7CA,CA8CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,KAxEA;AA0EA,IAAA,mBAAA,EAAA,+BAAA;AACA;AACA;AACA,MAAA,OAAA,CAAA,GAAA,CAAA,CACA,OAAA,CAAA,IAAA,CAAA,gBAAA,CAAA,WAAA,CAAA,SAAA,CADA,EAEA,OAAA,CAAA,IAAA,CAAA,iBAAA,CAAA,WAAA,CAAA,SAAA,CAFA,EAGA,OAAA,CAAA,IAAA,CAAA,kBAAA,CAAA,WAAA,CAAA,SAAA,CAHA,EAIA,OAAA,CAAA,IAAA,CAAA,iBAAA,CAAA,WAAA,CAAA,SAAA,CAJA,CAAA,EAKA,IALA,CAKA,OAAA,CAAA,GAAA,CAAA,cAAA,CALA;AAMA,KAnFA;AAoFA,IAAA,WAAA,EAAA,uBAAA;AACA,MAAA,SAAA,CAAA,YAAA,CACA;AAAA,QAAA,KAAA,EAAA;AAAA,OADA,EAEA,UAAA,MAAA;AAAA,eAAA,KAAA,CAAA,SAAA,GAAA,MAAA;AAAA,OAFA,EAGA,UAAA,GAAA;AAAA,eAAA,OAAA,CAAA,KAAA,CAAA,GAAA,CAAA;AAAA,OAHA;AAKA,KA1FA;AA2FA,IAAA,wBAAA,EAAA,oCAAA;AACA;AACA,UAAA,IAAA,GAAA,IAAA;;AACA,UAAA,IAAA,CAAA,UAAA,EAAA;AACA;AACA,QAAA,IAAA,CAAA,kBAAA,IAAA,CAAA,CAFA,CAGA;AACA;;AACA,YAAA,MAAA,GAAA,IAAA,CAAA,KAAA,CAAA,cAAA;AACA,YAAA,OAAA,GAAA,MAAA,CAAA,UAAA,CAAA,IAAA,CAAA;AACA,QAAA,OAAA,CAAA,SAAA,CAAA,CAAA,EAAA,CAAA,EAAA,MAAA,CAAA,KAAA,EAAA,MAAA,CAAA,MAAA;AACA,YAAA,GAAA,GAAA,IAAA,CAAA,UAAA,CAAA,SAAA,CAAA,GAAA,CARA,CAUA;AACA;;AACA,QAAA,OAAA,CAAA,SAAA,CACA,IAAA,CAAA,KAAA,CAAA,KADA,EAEA,GAAA,CAAA,CAFA,EAGA,GAAA,CAAA,CAHA,EAIA,GAAA,CAAA,KAJA,EAKA,GAAA,CAAA,MALA,EAMA,GAAA,CAAA,CANA,EAOA,GAAA,CAAA,CAPA,EAQA,GAAA,CAAA,KARA,EASA,GAAA,CAAA,MATA,EAZA,CAwBA;AACA;AACA;AACA;AACA;AAEA;AACA;;AACA,YAAA,aAAA,GAAA,CAAA,GAAA,CAAA,GAAA,EAAA,GAAA,CAAA,KAAA,EAAA,GAAA,CAAA,MAAA,EAAA,GAAA,CAAA,IAAA,CAAA,CAhCA,CAqCA;;AACA,QAAA,IAAA,CAAA,KAAA,CAAA,cAAA,CAAA,MAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCAAA,iBAAA,IAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA,oBAAA,QAJA,GAIA,IAAA,QAAA,EAJA,EAKA;;AACA,oBAAA,QAAA,CAAA,MAAA,CACA,MADA,EAEA,IAFA,EAGA,kBAAA,IAAA,CAAA,kBAAA,GAAA,MAHA;AAKA,oBAAA,QAAA,CAAA,MAAA,CAAA,YAAA,EAAA,IAAA,CAAA,UAAA;AACA,oBAAA,QAAA,CAAA,MAAA,CAAA,eAAA,EAAA,aAAA;AACA,oBAAA,IAAA,CAAA,KAAA,CAAA;AACA,sBAAA,GAAA,EAAA,IAAA,CAAA,QAAA,GAAA,sBADA;AAEA,sBAAA,MAAA,EAAA,MAFA;AAGA,sBAAA,IAAA,EAAA;AAHA,qBAAA;;AAbA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,WAAA;;AAAA;AAAA;AAAA;AAAA;AAmBA;AACA,KAxJA;AAyJA,IAAA,sBAAA,EAAA,kCAAA;AAAA;;AACA,WAAA,KAAA,CAAA;AACA,QAAA,GAAA,EAAA,KAAA,QAAA,GAAA,sBADA;AAEA,QAAA,MAAA,EAAA,MAFA;AAGA,QAAA,IAAA,EAAA;AAAA,UAAA,UAAA,EAAA,KAAA;AAAA;AAHA,OAAA,EAIA,IAJA,CAIA,UAAA,QAAA,EAAA;AACA,YAAA,QAAA,CAAA,IAAA,CAAA,KAAA,EAAA;AACA,UAAA,KAAA,CAAA,cAAA,GAAA,QAAA,CAAA,IAAA,CAAA,IAAA;AACA;AACA,OARA;AASA,KAnKA;AAoKA,IAAA,YAAA,EAAA,wBAAA;AACA,MAAA,OAAA,CAAA,GAAA,CAAA,KAAA,eAAA;AACA,KAtKA;AAuKA,IAAA,qBAAA,EAAA,iCAAA;AACA,MAAA,OAAA,CAAA,GAAA,CAAA,uBAAA,EADA,CAEA;AACA;AACA;;AACA,UAAA,IAAA,GAAA,IAAA;AAEA,MAAA,WAAA;AAAA;AAAA;AAAA;AAAA,8BAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uBAGA,OAAA,CACA,gBADA,CAEA,IAAA,CAAA,KAAA,CAAA,KAFA,EAGA,IAAA,OAAA,CAAA,uBAAA,EAHA,EAKA,iBALA,GAMA,mBANA,EAHA;;AAAA;AAGA,gBAAA,IAAA,CAAA,UAHA;;AAUA;AACA;AAEA,oBAAA,IAAA,CAAA,UAAA,EAAA;AACA,kBAAA,IAAA,CAAA,QAAA,GAAA,IAAA,CADA,CAEA;;AACA,kBAAA,iBAHA,GAGA,OAAA,CAAA,aAAA,CACA,IAAA,CAAA,UADA,EAEA,IAAA,CAAA,YAFA,CAHA,EAQA;;AACA,kBAAA,IAAA,CAAA,UAAA,GAAA,iBAAA,CATA,CAWA;;AACA,kBAAA,IAAA,CAAA,gBAAA;AACA,kBAAA,IAAA,CAAA,oBAAA;AACA,kBAAA,IAAA,CAAA,eAAA,GAdA,CAgBA;;AACA,kBAAA,QAjBA,GAiBA,CACA,UAAA,IAAA,CAAA,yBAAA,CAAA,iBADA,EAEA,UAAA,IAAA,CAAA,yBAAA,CAAA,cAFA,EAGA,iBAAA,IAAA,CAAA,yBAAA,CAAA,UAHA,EAIA,YAAA,IAAA,CAAA,yBAAA,CAAA,KAJA,EAKA,cAAA,IAAA,CAAA,yBAAA,CAAA,OALA,CAjBA;AAwBA,kBAAA,OAxBA,GAwBA,OAxBA,EAyBA;;AACA,sBAAA,IAAA,CAAA,YAAA,CAAA,MAAA,IAAA,CAAA,IAAA,IAAA,CAAA,cAAA,IAAA,EAAA,EAAA;AACA,oBAAA,OAAA,GAAA,YAAA,IAAA,CAAA,gBAAA,GAAA,GAAA;AACA,mBAFA,MAEA,IACA,IAAA,CAAA,YAAA,CAAA,MAAA,IAAA,CAAA,IACA,IAAA,CAAA,cAAA,IAAA,EAFA,EAGA;AACA,oBAAA,OAAA,GAAA,wDAAA;AACA;;AAEA,kBAAA,IAAA,CAAA,UAAA,CAAA;AACA,oBAAA,KAAA,EAAA,KADA;AAEA,oBAAA,OAAA,EAAA,OAFA;AAGA,oBAAA,QAAA,EAAA;AAHA,mBAAA,EAnCA,CAyCA;;AACA,sBAAA,IAAA,CAAA,YAAA,CAAA,MAAA,IAAA,CAAA,EAAA;AACA,wBAAA,IAAA,CAAA,aAAA,EAAA,EAAA;AACA,sBAAA,IAAA,CAAA,YAAA,CAAA,KAAA;AACA,sBAAA,IAAA,CAAA,sBAAA;AACA;AACA;AACA,iBAhDA,MAgDA;AACA,kBAAA,IAAA,CAAA,UAAA,CAAA;AAAA,oBAAA,KAAA,EAAA;AAAA,mBAAA;AACA;;AA/DA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAAA,IAgEA,IAAA,CAAA,YAhEA,CAAA;AAiEA,KA/OA;AAgPA;AACA,IAAA,UAAA,EAAA,2BAAA;AAAA,8BAAA,KAAA;AAAA,UAAA,KAAA,4BAAA,KAAA;AAAA,gCAAA,OAAA;AAAA,UAAA,OAAA,8BAAA,QAAA;AAAA,iCAAA,QAAA;AAAA,UAAA,QAAA,+BAAA,EAAA;AACA,UAAA,MAAA,GAAA,KAAA,KAAA,CAAA,MAAA;AACA,UAAA,WAAA,GAAA,KAAA,KAAA,CAAA,WAAA,CAFA,CAIA;;AACA,MAAA,MAAA,CAAA,UAAA,CAAA,IAAA,EAAA,SAAA,CAAA,CAAA,EAAA,CAAA,EAAA,MAAA,CAAA,KAAA,EAAA,MAAA,CAAA,MAAA;AACA,MAAA,WAAA,CACA,UADA,CACA,IADA,EAEA,SAFA,CAEA,CAFA,EAEA,CAFA,EAEA,WAAA,CAAA,KAFA,EAEA,WAAA,CAAA,MAFA,EANA,CAUA;;AACA,UAAA,KAAA,KAAA,KAAA,EAAA;AACA;AACA,QAAA,OAAA,CAAA,IAAA,CAAA,iBAAA,CAAA,WAAA,EAAA,KAAA,UAAA,EAFA,CAIA;;AACA,YAAA,GAAA,GAAA,KAAA,UAAA,CAAA,SAAA,CAAA,GAAA,CALA,CAMA;;AACA,YAAA,aAAA,GAAA;AACA,UAAA,CAAA,EAAA,MAAA,CAAA,KAAA,GAAA,GAAA,CAAA,CAAA,GAAA,GAAA,CAAA,KADA;AAEA,UAAA,CAAA,EAAA,GAAA,CAAA,CAFA;AAGA,UAAA,KAAA,EAAA,GAAA,CAAA,KAHA;AAIA,UAAA,MAAA,EAAA,GAAA,CAAA;AAJA,SAAA,CAPA,CAaA;;AACA,YAAA,UAAA,GAAA;AACA,UAAA,KAAA,EAAA,OADA;AAEA,UAAA,SAAA,EAAA,CAFA;AAGA,UAAA,QAAA,EAAA;AAHA,SAAA,CAdA,CAmBA;;AACA,YAAA,OAAA,GAAA,IAAA,OAAA,CAAA,IAAA,CAAA,OAAA,CAAA,aAAA,EAAA,UAAA,CAAA;AACA,QAAA,OAAA,CAAA,IAAA,CAAA,MAAA,EArBA,CAuBA;;AACA,YAAA,QAAA,CAAA,MAAA,IAAA,CAAA,EAAA;AACA,cAAA,IAAA,GAAA,QAAA;AACA,cAAA,MAAA,GAAA,KAAA,UAAA,CAAA,SAAA,CAAA,GAAA,CAAA,UAAA;AACA,cAAA,gBAAA,GAAA;AACA,YAAA,CAAA,EAAA,MAAA,CAAA,KAAA,GAAA,MAAA,CAAA,CAAA,GAAA,GAAA,CAAA,KADA;AAEA,YAAA,CAAA,EAAA,MAAA,CAAA;AAFA,WAAA,CAHA,CAOA;;AACA,cAAA,WAAA,GAAA;AACA,YAAA,cAAA,EAAA,UADA;AAEA,YAAA,eAAA,EAAA;AAFA,WAAA;AAIA,cAAA,QAAA,GAAA,IAAA,OAAA,CAAA,IAAA,CAAA,aAAA,CACA,IADA,EAEA,gBAFA,EAGA,WAHA,CAAA;AAKA,UAAA,QAAA,CAAA,IAAA,CAAA,MAAA;AACA;AACA;AACA,KAxSA;AAySA,IAAA,eAAA,EAAA,2BAAA;AACA,UAAA,WAAA,GAAA,KAAA,UAAA,CAAA,WAAA,CADA,CAEA;AACA;AACA;;AACA,UAAA,iBAAA,GAAA,MAAA,CAAA,IAAA,CAAA,WAAA,EAAA,MAAA,CAAA,UAAA,CAAA,EAAA,CAAA;AAAA,eACA,WAAA,CAAA,CAAA,CAAA,GAAA,WAAA,CAAA,CAAA,CAAA,GAAA,CAAA,GAAA,CADA;AAAA,OAAA,CAAA;AAGA,UAAA,sBAAA,GAAA,WAAA,CAAA,iBAAA,CAAA;AACA,WAAA,yBAAA,CAAA,YAAA,IAAA,iBAAA;AAEA,aAAA,iBAAA,GAAA,GAAA,GAAA,MAAA,CAAA,sBAAA,CAAA;AACA,KArTA;AAsTA,IAAA,oBAAA,EAAA,gCAAA;AACA,UAAA,SAAA,GAAA,KAAA,UAAA,CAAA,SAAA;AACA,UAAA,iBAAA,GAAA,SAAA,CAAA,SAAA,CAFA,CAIA;;AACA,UAAA,mBAAA,GAAA,OAAA,CAAA,iBAAA,CACA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,EAAA,CAAA,CADA,EAEA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,EAAA,CAAA,CAFA,CAAA;AAIA,UAAA,kBAAA,GAAA,OAAA,CAAA,iBAAA,CACA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,CAAA,CAAA,CADA,EAEA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,EAAA,CAAA,CAFA,CAAA;AAIA,UAAA,wBAAA,GAAA,mBAAA,GAAA,kBAAA,CAbA,CAeA;;AACA,UAAA,eAAA,GACA,CAAA,iBAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,iBAAA,CAAA,CAAA,CAAA,CAAA,CAAA,KACA,iBAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,iBAAA,CAAA,CAAA,CAAA,CAAA,CADA,CADA;AAGA,UAAA,gBAAA,GACA,CAAA,iBAAA,CAAA,EAAA,CAAA,CAAA,CAAA,GAAA,iBAAA,CAAA,CAAA,CAAA,CAAA,CAAA,KACA,iBAAA,CAAA,EAAA,CAAA,CAAA,CAAA,GAAA,iBAAA,CAAA,CAAA,CAAA,CAAA,CADA,CADA;AAGA,UAAA,kBAAA,GAAA,CAAA,eAAA,GAAA,gBAAA,IAAA,CAAA,CAtBA,CAuBA;;AAEA,UACA,wBAAA,GAAA,IAAA,KAAA,wBAAA,IACA,wBAAA,GAAA,KAAA,wBAFA,EAGA;AACA,aAAA,yBAAA,CAAA,mBAAA,IAAA,SAAA;AACA,OALA,MAKA,IAAA,wBAAA,GAAA,KAAA,wBAAA,EAAA;AACA,aAAA,yBAAA,CAAA,mBAAA,IAAA,OAAA;AACA,OAFA,MAEA,IAAA,wBAAA,GAAA,IAAA,KAAA,wBAAA,EAAA;AACA,aAAA,yBAAA,CAAA,mBAAA,IAAA,MAAA;AACA;;AACA,UAAA,kBAAA,GAAA,KAAA,kBAAA,EAAA;AACA,aAAA,yBAAA,CAAA,gBAAA,IAAA,IAAA;AACA,OAFA,MAEA,IAAA,kBAAA,GAAA,KAAA,oBAAA,EAAA;AACA,aAAA,yBAAA,CAAA,gBAAA,IAAA,MAAA;AACA,OAFA,MAEA;AACA,aAAA,yBAAA,CAAA,gBAAA,IAAA,SAAA;AACA;AACA,KAhWA;AAiWA,IAAA,gBAAA,EAAA,4BAAA;AACA;AACA,UAAA,SAAA,GAAA,KAAA,UAAA,CAAA,SAAA;AACA,UAAA,iBAAA,GAAA,SAAA,CAAA,SAAA,CAHA,CAIA;;AACA,UAAA,OAAA,GAAA,OAAA,CAAA,iBAAA,CACA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,EAAA,CAAA,CADA,EAEA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,EAAA,CAAA,CAFA,CAAA;AAIA,UAAA,OAAA,GAAA,OAAA,CAAA,iBAAA,CACA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,EAAA,CAAA,CADA,EAEA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,EAAA,CAAA,CAFA,CAAA;AAIA,UAAA,kBAAA,GAAA,OAAA,GAAA,OAAA;;AACA,UAAA,kBAAA,GAAA,KAAA,eAAA,EAAA;AACA,aAAA,yBAAA,CAAA,KAAA,GAAA,MAAA;AACA,OAFA,MAEA;AACA,aAAA,yBAAA,CAAA,KAAA,GAAA,SAAA;AACA,OAlBA,CAoBA;AACA;;;AACA,UAAA,eAAA,GAAA,OAAA,CAAA,iBAAA,CACA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,EAAA,CAAA,CADA,EAEA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,EAAA,CAAA,CAFA,CAAA;AAIA,UAAA,eAAA,GAAA,OAAA,CAAA,iBAAA,CACA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,EAAA,CAAA,CADA,EAEA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,EAAA,CAAA,CAFA,CAAA,CA1BA,CA8BA;;AACA,UAAA,OAAA,GAAA,OAAA,CAAA,iBAAA,CACA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,EAAA,CAAA,CADA,EAEA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,EAAA,CAAA,CAFA,CAAA;AAIA,UAAA,OAAA,GAAA,OAAA,CAAA,iBAAA,CACA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,EAAA,CAAA,CADA,EAEA,MAAA,CAAA,MAAA,CAAA,iBAAA,CAAA,EAAA,CAAA,CAFA,CAAA;AAIA,UAAA,qBAAA,GACA,CAAA,eAAA,GAAA,eAAA,KAAA,OAAA,GAAA,OAAA,CADA;;AAGA,UAAA,qBAAA,GAAA,KAAA,iBAAA,EAAA;AACA,aAAA,yBAAA,CAAA,OAAA,GAAA,QAAA;AACA,OAFA,MAEA;AACA,aAAA,yBAAA,CAAA,OAAA,GAAA,SAAA;AACA;AACA,KAhZA;AAiZA,IAAA,wBAAA,EAAA,oCAAA;AACA,MAAA,OAAA,CAAA,GAAA,CAAA,KAAA,UAAA;AACA,UAAA,eAAA,GAAA,IAAA,CAAA,SAAA,CAAA,KAAA,UAAA,CAAA;AACA,UAAA,IAAA,GAAA,IAAA,IAAA,CAAA,CAAA,eAAA,CAAA,EAAA;AAAA,QAAA,IAAA,EAAA;AAAA,OAAA,CAAA;AACA,MAAA,SAAA,CAAA,MAAA,CAAA,IAAA,EAAA,UAAA;AACA;AAtZA;AAlEA,CAAA","sourcesContent":["<template>\r\n  <div>\r\n    <v-container id=\"overlay\" fluid v-if=\"!detected\">\r\n      <v-layout align-center justify-center row fill-height id=\"overlay_content\">\r\n        <v-flex xs1>\r\n          <v-fa-icon name=\"robot\" scale=\"3\"/>\r\n        </v-flex>\r\n        <v-flex xs10>\r\n          <label class=\"display-3\">AI is getting ready, let the camera see you</label>\r\n        </v-flex>\r\n        <v-flex xs1>\r\n          <v-fa-icon name=\"camera\" scale=\"3\"/>\r\n        </v-flex>\r\n      </v-layout>\r\n    </v-container>\r\n    <v-container grid-list-md text-xs-center fluid>\r\n      <v-layout justify-center v-if=\"current_instruction.command.length != 0\" class=\"display-2\">\r\n        <label>\r\n          Instruction: {{current_instruction.command}}\r\n          <v-fa-icon :name=\"current_instruction.icon\" scale=\"3\"/>\r\n        </label>\r\n      </v-layout>\r\n      <v-layout justify-center>\r\n        <video\r\n          id=\"video\"\r\n          ref=\"video\"\r\n          :width=\"display_size.width\"\r\n          :height=\"display_size.height\"\r\n          v-if=\"true\"\r\n          autoplay\r\n          @play=\"detect_and_draw_faces\"\r\n        ></video>\r\n\r\n        <canvas\r\n          id=\"canvas_flip\"\r\n          ref=\"canvas_flip\"\r\n          :width=\"display_size.width\"\r\n          :height=\"display_size.height\"\r\n        />\r\n        <canvas id=\"canvas\" ref=\"canvas\" :width=\"display_size.width\" :height=\"display_size.height\"/>\r\n        <!-- third canvas just for image capturing -->\r\n        <canvas\r\n          id=\"canvas_capture\"\r\n          ref=\"canvas_capture\"\r\n          :width=\"display_size.width\"\r\n          :height=\"display_size.height\"\r\n        />\r\n      </v-layout>\r\n      <v-layout align-center justify-center>\r\n        <v-flex xs4></v-flex>\r\n      </v-layout>\r\n    </v-container>\r\n  </div>\r\n</template>\r\n\r\n<script>\r\n// useful tutorial: https://www.youtube.com/watch?v=CVClHLwv-4I&feature=youtu.be\r\n// https://github.com/WebDevSimplified/Face-Detection-JavaScript/blob/master/script.js\r\n\r\nimport * as faceapi from \"face-api.js\";\r\nimport { async } from \"q\";\r\nimport { setTimeout, setInterval } from \"timers\";\r\nimport FileSaver from \"file-saver\";\r\nimport Icon from \"vue-awesome/components/Icon\";\r\nimport vue2Dropzone from \"vue2-dropzone\";\r\nimport \"vue2-dropzone/dist/vue2Dropzone.min.css\";\r\n\r\nexport default {\r\n  name: \"FaceDetection\",\r\n  components: {\r\n    \"v-fa-icon\": Icon,\r\n    vueDropzone: vue2Dropzone\r\n  },\r\n  data: function() {\r\n    return {\r\n      display_size: { width: 640, height: 480 },\r\n      detections: [],\r\n      temp_detections: [],\r\n      capture_file_count: 0,\r\n      detected: false,\r\n      resizedDetections: [],\r\n      confirmed_user: \"\",\r\n      refresh_time: 50,\r\n      // determine sensitivity for left and right face, higher = more turning needed\r\n      left_right_turning_ratio: 2,\r\n      // determine sensitivity for look up, higher = more turning needed\r\n      up_slope_threshold: -0.1,\r\n      down_slope_threshold: -0.55,\r\n      // larger the more opening\r\n      mouth_threshold: 0.7,\r\n      // larger the more opening\r\n      eyebrow_threshold: 1.0,\r\n      // List of available instructions\r\n      instructions: [\r\n        { command: \"Turn Left!\", icon: \"arrow-alt-circle-left\" },\r\n        { command: \"Turn Right!\", icon: \"arrow-alt-circle-right\" },\r\n        { command: \"Look Up!\", icon: \"arrow-alt-circle-up\" },\r\n        { command: \"Look Down!\", icon: \"arrow-alt-circle-down\" },\r\n        { command: \"Smile!\", icon: \"laugh\" },\r\n        { command: \"Open mouth!\", icon: \"teeth-open\" }\r\n\r\n        // \"Raise eyebrows!\"\r\n      ],\r\n      current_instruction: { command: \"\", icon: \"\" },\r\n      liveness_detection_status: {\r\n        left_right_status: \"neutral\",\r\n        up_down_status: \"neutral\",\r\n        expression: \"neutral\",\r\n        mouth: \"neutral\",\r\n        eyebrow: \"neutral\"\r\n      },\r\n      liveness_test_instructions: []\r\n    };\r\n  },\r\n  watch: {\r\n    temp_detections: function(new_val, old_val) {\r\n      console.log(new_val);\r\n    }\r\n  },\r\n  mounted: function() {\r\n    this.load_faceapi_models();\r\n    this.start_video();\r\n    this.generate_liveness_test();\r\n  },\r\n  computed: {\r\n    session_id() {\r\n      // session_id should be sent to all the axios request to backend now\r\n      return this.$store.state.session_id;\r\n    },\r\n      user_name_in_key(){\r\n      return this.$store.state.user_name_in_key;\r\n    }\r\n  },\r\n  methods: {\r\n    generate_liveness_test: function() {\r\n      // DEBUG: add a timer for each test?\r\n      function shuffleArray(array) {\r\n        for (let i = array.length - 1; i > 0; i--) {\r\n          const j = Math.floor(Math.random() * (i + 1));\r\n          [array[i], array[j]] = [array[j], array[i]];\r\n        }\r\n      }\r\n      if (this.instructions.length == 0) {\r\n        console.log(\"you are a human!\");\r\n        this.current_instruction.command = \"\";\r\n        this.match_known_descriptor();\r\n      } else {\r\n        shuffleArray(this.instructions);\r\n        this.current_instruction = this.instructions[0];\r\n      }\r\n    },\r\n    liveness_test: function() {\r\n      var test = this.current_instruction.command;\r\n      var result = this.liveness_detection_status;\r\n      // use the neutral pose to ensure we don't get false detection\r\n      var neutral_l_r_pose = result.left_right_status == \"neutral\";\r\n      var neutral_u_d_pose = result.up_down_status == \"neutral\";\r\n      var neutral_mouth = result.mouth == \"neutral\";\r\n\r\n      if (test == \"Turn Left!\" && result.left_right_status == \"left\") {\r\n        this.generate_face_descriptor();\r\n        return true;\r\n      } else if (test == \"Turn Right!\" && result.left_right_status == \"right\") {\r\n        this.generate_face_descriptor();\r\n        return true;\r\n      } else if (\r\n        test == \"Look Up!\" &&\r\n        result.up_down_status == \"up\" &&\r\n        neutral_l_r_pose &&\r\n        neutral_mouth\r\n      ) {\r\n        this.generate_face_descriptor();\r\n        return true;\r\n      } else if (\r\n        test == \"Look Down!\" &&\r\n        result.up_down_status == \"down\" &&\r\n        neutral_l_r_pose &&\r\n        neutral_mouth\r\n      ) {\r\n        this.generate_face_descriptor();\r\n        return true;\r\n      } else if (\r\n        test == \"Smile!\" &&\r\n        result.expression == \"happy\" &&\r\n        neutral_l_r_pose &&\r\n        neutral_u_d_pose\r\n      ) {\r\n        this.generate_face_descriptor();\r\n        return true;\r\n      } else if (\r\n        test == \"Open mouth!\" &&\r\n        result.mouth == \"open\" &&\r\n        neutral_l_r_pose\r\n      ) {\r\n        this.generate_face_descriptor();\r\n        return true;\r\n      }\r\n      // } else if (\r\n      //   test == \"Raise eyebrows!\" &&\r\n      //   result.eyebrow == \"raised\" &&\r\n      //   neutral_l_r_pose &&\r\n      //   neutral_u_d_pose\r\n      // ) {\r\n      //   return true;\r\n      // }\r\n    },\r\n\r\n    load_faceapi_models: function() {\r\n      // save the models to the public/models\r\n      // faceapi.nets.ssdMobilenetv1.loadFromUri(\"/models\"),\r\n      Promise.all([\r\n        faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\"),\r\n        faceapi.nets.faceLandmark68Net.loadFromUri(\"/models\"),\r\n        faceapi.nets.faceRecognitionNet.loadFromUri(\"/models\"),\r\n        faceapi.nets.faceExpressionNet.loadFromUri(\"/models\")\r\n      ]).then(console.log(\"model loaded\"));\r\n    },\r\n    start_video: function() {\r\n      navigator.getUserMedia(\r\n        { video: {} },\r\n        stream => (video.srcObject = stream),\r\n        err => console.error(err)\r\n      );\r\n    },\r\n    generate_face_descriptor: function() {\r\n      // https://x-team.com/blog/webcam-capture-vue/\r\n      let self = this;\r\n      if (self.detections) {\r\n        // keep track how many images we have captured\r\n        self.capture_file_count += 1;\r\n        // console.log(this.detections);\r\n        // console.log(self.capture_file_count);\r\n        const canvas = self.$refs.canvas_capture;\r\n        var context = canvas.getContext(\"2d\");\r\n        context.clearRect(0, 0, canvas.width, canvas.height);\r\n        var box = self.detections.detection.box;\r\n\r\n        // Sending the face with cropped region \r\n        // drawImage from the video stream, with cropping\r\n        context.drawImage(\r\n          self.$refs.video,\r\n          box.x,\r\n          box.y,\r\n          box.width,\r\n          box.height,\r\n          box.x,\r\n          box.y,\r\n          box.width,\r\n          box.height\r\n        );\r\n\r\n        // // sending the whole image \r\n        //   context.drawImage(\r\n        //   self.$refs.video,\r\n        //   0, 0, self.display_size['width'], self.display_size['height']\r\n        // );\r\n\r\n        // // // sending the face_location to backend to save some repetition \r\n        // // // top, right, bottom, left\r\n        const face_location = [box.top, box.right, box.bottom, box.left]\r\n\r\n\r\n\r\n\r\n        // Saving canvas to local drive is easy: https://github.com/eligrey/FileSaver.js/\r\n        self.$refs.canvas_capture.toBlob(async function(blob) {\r\n          // result = await faceapi.bufferToImage(blob).\r\n          // upload Blob as a form to the flask backend and generate descriptors\r\n          // https://github.com/pagekit/vue-resource/blob/master/docs/recipes.md\r\n          let formData = new FormData();\r\n          // formData.append(name, value, filename);\r\n          formData.append(\r\n            \"file\",\r\n            blob,\r\n            \"unknown_face_\" + self.capture_file_count + \".jpg\"\r\n          );\r\n          formData.append(\"session_id\", self.session_id);\r\n          formData.append(\"face_location\", face_location);\r\n          self.axios({\r\n            url: self.$API_URL + \"/generate_descriptor\",\r\n            method: \"POST\",\r\n            data: formData\r\n          });\r\n        });\r\n      }\r\n    },\r\n    match_known_descriptor: function() {\r\n      this.axios({\r\n        url: this.$API_URL + \"/compare_descriptors\",\r\n        method: \"POST\",\r\n        data: {session_id: this.session_id}\r\n      }).then(response => {\r\n        if (response.data.match) {\r\n          this.confirmed_user = response.data.user;\r\n        }\r\n      });\r\n    },\r\n    show_capture: function() {\r\n      console.log(this.temp_detections);\r\n    },\r\n    detect_and_draw_faces: function() {\r\n      console.log(\"start detecting faces\");\r\n      // https://michaelnthiessen.com/this-is-undefined/\r\n      // https://stackoverflow.com/questions/47148363/when-to-use-vm-or-this-in-vue-js\r\n      // arrow function is a pain in vue.js and this async function also seems to cause problem\r\n      let self = this;\r\n\r\n      setInterval(async function() {\r\n        //  After face detection and facial landmark prediction the face descriptors\r\n        //  all the results are stored in self.detections\r\n        self.detections = await faceapi\r\n          .detectSingleFace(\r\n            self.$refs.video,\r\n            new faceapi.TinyFaceDetectorOptions()\r\n          )\r\n          .withFaceLandmarks()\r\n          .withFaceExpressions();\r\n        // calculating the 128 descriptors seems to be rather slow, lets not do it very frequent or do it in backend\r\n        // .withFaceDescriptors();\r\n\r\n        if (self.detections) {\r\n          self.detected = true;\r\n          // calculated the size that is on our canvas size\r\n          const resizedDetections = faceapi.resizeResults(\r\n            self.detections,\r\n            self.display_size\r\n          );\r\n\r\n          // replace the result with scaled one, all the other information will remain\r\n          self.detections = resizedDetections;\r\n\r\n          // call other methods\r\n          self.mouth_eye_status();\r\n          self.head_pose_estimation();\r\n          self.find_expression();\r\n\r\n          // annotation\r\n          var message2 = [\r\n            \"L/R: \" + self.liveness_detection_status.left_right_status,\r\n            \"U/D: \" + self.liveness_detection_status.up_down_status,\r\n            \"Expression: \" + self.liveness_detection_status.expression,\r\n            \"mouth: \" + self.liveness_detection_status.mouth,\r\n            \"eyebrow: \" + self.liveness_detection_status.eyebrow\r\n          ];\r\n          var message = \"Hello\";\r\n          // only append the username after liveness test\r\n          if (self.instructions.length == 0 && self.confirmed_user != \"\") {\r\n            message = \"Hello: \" + self.user_name_in_key + \"!\";\r\n          } else if (\r\n            self.instructions.length == 0 &&\r\n            self.confirmed_user == \"\"\r\n          ) {\r\n            message = \"Hello: Stranger! Maybe you are not who you claim to be\";\r\n          }\r\n\r\n          self.annotation({\r\n            clear: false,\r\n            message: message,\r\n            message2: message2\r\n          });\r\n\r\n          // liveness test is passed, we move on with next test\r\n          if (self.instructions.length != 0) {\r\n            if (self.liveness_test()) {\r\n              self.instructions.shift();\r\n              self.generate_liveness_test();\r\n            }\r\n          }\r\n        } else {\r\n          self.annotation({ clear: true });\r\n        }\r\n      }, self.refresh_time);\r\n    },\r\n    // note how to use named arguments in javascript...\r\n    annotation: function({ clear = false, message = \"Hello!\", message2 = [] }) {\r\n      var canvas = this.$refs.canvas;\r\n      var canvas_flip = this.$refs.canvas_flip;\r\n\r\n      // clear canvas before drawing the new things to prevent cluttering\r\n      canvas.getContext(\"2d\").clearRect(0, 0, canvas.width, canvas.height);\r\n      canvas_flip\r\n        .getContext(\"2d\")\r\n        .clearRect(0, 0, canvas_flip.width, canvas_flip.height);\r\n\r\n      // set to clear when no face can be found\r\n      if (clear === false) {\r\n        // NOTE: There are some useful drawing functions already exist\r\n        faceapi.draw.drawFaceLandmarks(canvas_flip, this.detections);\r\n\r\n        // Draw box around the face with 1 line text\r\n        const box = this.detections.detection.box;\r\n        // mirror X\r\n        const box_X_flipped = {\r\n          x: canvas.width - box.x - box.width,\r\n          y: box.y,\r\n          width: box.width,\r\n          height: box.height\r\n        };\r\n        // see DrawBoxOptions below\r\n        const boxOptions = {\r\n          label: message,\r\n          lineWidth: 2,\r\n          boxColor: \"rgba(57,255,20,0.8)\"\r\n        };\r\n        // flip the x-value x, y, width, height\r\n        const drawBox = new faceapi.draw.DrawBox(box_X_flipped, boxOptions);\r\n        drawBox.draw(canvas);\r\n\r\n        // ------- multi-line text at bottom -------\r\n        if (message2.length != 0) {\r\n          const text = message2;\r\n          const anchor = this.detections.detection.box.bottomLeft;\r\n          const anchor_X_flipped = {\r\n            x: canvas.width - anchor.x - box.width,\r\n            y: anchor.y\r\n          };\r\n          // see DrawTextField below\r\n          const textOptions = {\r\n            anchorPosition: \"TOP_LEFT\",\r\n            backgroundColor: \"rgba(57,255,20, 0.5)\"\r\n          };\r\n          const drawText = new faceapi.draw.DrawTextField(\r\n            text,\r\n            anchor_X_flipped,\r\n            textOptions\r\n          );\r\n          drawText.draw(canvas);\r\n        }\r\n      }\r\n    },\r\n    find_expression: function() {\r\n      var expressions = this.detections.expressions;\r\n      // find the max value of all the keys\r\n      // The reducer function takes four arguments: Accumulator (acc), Current Value (cur), Current Index (idx)\r\n      // the question mark is conditional operator, which returns true_val:false_val\r\n      var likely_expression = Object.keys(expressions).reduce((i, j) =>\r\n        expressions[i] > expressions[j] ? i : j\r\n      );\r\n      var expression_possibility = expressions[likely_expression];\r\n      this.liveness_detection_status[\"expression\"] = likely_expression;\r\n\r\n      return likely_expression + \":\" + String(expression_possibility);\r\n    },\r\n    head_pose_estimation: function() {\r\n      const landmarks = this.detections.landmarks;\r\n      const landmarkPositions = landmarks.positions;\r\n\r\n      // the distance between 1 and 28 will be shorter when extending left face\r\n      const right_face_distance = faceapi.euclideanDistance(\r\n        Object.values(landmarkPositions[16]),\r\n        Object.values(landmarkPositions[28])\r\n      );\r\n      const left_face_distance = faceapi.euclideanDistance(\r\n        Object.values(landmarkPositions[0]),\r\n        Object.values(landmarkPositions[28])\r\n      );\r\n      const right_to_left_face_ratio = right_face_distance / left_face_distance;\r\n\r\n      // the point 6 - 12 become more flat when facing upward. calculate the slope\r\n      const chin_slope_left =\r\n        (landmarkPositions[5].y - landmarkPositions[8].y) /\r\n        (landmarkPositions[8].x - landmarkPositions[5].x);\r\n      const chin_slope_right =\r\n        (landmarkPositions[11].y - landmarkPositions[8].y) /\r\n        (landmarkPositions[11].x - landmarkPositions[8].x);\r\n      const chin_slope_average = (chin_slope_left + chin_slope_right) / 2;\r\n      // NOTE: make this vue variable\r\n\r\n      if (\r\n        right_to_left_face_ratio > 1 / this.left_right_turning_ratio &&\r\n        right_to_left_face_ratio < this.left_right_turning_ratio\r\n      ) {\r\n        this.liveness_detection_status[\"left_right_status\"] = \"neutral\";\r\n      } else if (right_to_left_face_ratio > this.left_right_turning_ratio) {\r\n        this.liveness_detection_status[\"left_right_status\"] = \"right\";\r\n      } else if (right_to_left_face_ratio < 1 / this.left_right_turning_ratio) {\r\n        this.liveness_detection_status[\"left_right_status\"] = \"left\";\r\n      }\r\n      if (chin_slope_average > this.up_slope_threshold) {\r\n        this.liveness_detection_status[\"up_down_status\"] = \"up\";\r\n      } else if (chin_slope_average < this.down_slope_threshold) {\r\n        this.liveness_detection_status[\"up_down_status\"] = \"down\";\r\n      } else {\r\n        this.liveness_detection_status[\"up_down_status\"] = \"neutral\";\r\n      }\r\n    },\r\n    mouth_eye_status: function() {\r\n      //  https://towardsdatascience.com/mouse-control-facial-movements-hci-app-c16b0494a971\r\n      var landmarks = this.detections.landmarks;\r\n      const landmarkPositions = landmarks.positions;\r\n      // https://www.pyimagesearch.com/2017/04/24/eye-blink-detection-opencv-python-dlib/\r\n      const mouth_y = faceapi.euclideanDistance(\r\n        Object.values(landmarkPositions[51]),\r\n        Object.values(landmarkPositions[57])\r\n      );\r\n      const mouth_x = faceapi.euclideanDistance(\r\n        Object.values(landmarkPositions[54]),\r\n        Object.values(landmarkPositions[48])\r\n      );\r\n      const mouth_aspect_ratio = mouth_y / mouth_x;\r\n      if (mouth_aspect_ratio > this.mouth_threshold) {\r\n        this.liveness_detection_status.mouth = \"open\";\r\n      } else {\r\n        this.liveness_detection_status.mouth = \"neutral\";\r\n      }\r\n\r\n      //  ------------- eyebrow measurment: use the distance between eyebrow and eye vs\r\n      // the width of the eyes (rather constant)  to test whether the eyebrows are raised\r\n      const l_eyebrow_eye_d = faceapi.euclideanDistance(\r\n        Object.values(landmarkPositions[19]),\r\n        Object.values(landmarkPositions[37])\r\n      );\r\n      const r_eyebrow_eye_d = faceapi.euclideanDistance(\r\n        Object.values(landmarkPositions[24]),\r\n        Object.values(landmarkPositions[44])\r\n      );\r\n      // use eyebrow as a reference point\r\n      const l_eye_w = faceapi.euclideanDistance(\r\n        Object.values(landmarkPositions[39]),\r\n        Object.values(landmarkPositions[36])\r\n      );\r\n      const r_eye_w = faceapi.euclideanDistance(\r\n        Object.values(landmarkPositions[42]),\r\n        Object.values(landmarkPositions[45])\r\n      );\r\n      const eyebrow_d_eye_w_ratio =\r\n        (l_eyebrow_eye_d + r_eyebrow_eye_d) / (l_eye_w + r_eye_w);\r\n\r\n      if (eyebrow_d_eye_w_ratio > this.eyebrow_threshold) {\r\n        this.liveness_detection_status.eyebrow = \"raised\";\r\n      } else {\r\n        this.liveness_detection_status.eyebrow = \"neutral\";\r\n      }\r\n    },\r\n    download_face_descriptor: function() {\r\n      console.log(this.detections);\r\n      var detections_json = JSON.stringify(this.detections);\r\n      var blob = new Blob([detections_json], { type: \"application/json\" });\r\n      FileSaver.saveAs(blob, \"key.json\");\r\n    },\r\n  }\r\n};\r\n</script>\r\n\r\n<style scoped>\r\n@import url(\"https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\");\r\n\r\n#video {\r\n  position: absolute;\r\n  /* flip the image so it is more natural */\r\n  transform: scaleX(-1);\r\n}\r\n\r\n#canvas {\r\n  /* for some reason, we dont need both to be absolute? */\r\n  /* position: absolute; */\r\n  pointer-events: none;\r\n  z-index: 2;\r\n}\r\n\r\n#canvas_flip {\r\n  position: absolute;\r\n  pointer-events: none;\r\n  z-index: 2;\r\n  transform: scaleX(-1);\r\n}\r\n#canvas_capture {\r\n  /* we dont need to see it */\r\n  position: absolute;\r\n  display: none;\r\n  z-index: 3;\r\n  transform: scaleX(-1);\r\n}\r\n\r\n#overlay {\r\n  position: fixed;\r\n  width: 100%; /* Full width (cover the whole page) */\r\n  height: 100%; /* Full height (cover the whole page) */\r\n  top: 0;\r\n  left: 0;\r\n  right: 0;\r\n  bottom: 0;\r\n  background: rgb(0, 0, 0) center center no-repeat;\r\n  opacity: 1;\r\n  z-index: 5;\r\n}\r\n\r\n#overlay_content {\r\n  z-index: 6;\r\n  opacity: 0.8;\r\n  color: white;\r\n}\r\n</style>\r\n"],"sourceRoot":"src/components"}]}