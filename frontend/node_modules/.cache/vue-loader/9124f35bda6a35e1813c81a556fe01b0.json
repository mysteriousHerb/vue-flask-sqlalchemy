{"remainingRequest":"C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\node_modules\\vue-loader\\lib\\index.js??vue-loader-options!C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\src\\components\\FaceDetection.vue?vue&type=script&lang=js&","dependencies":[{"path":"C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\src\\components\\FaceDetection.vue","mtime":1560457583433},{"path":"C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\node_modules\\cache-loader\\dist\\cjs.js","mtime":1560457563834},{"path":"C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\node_modules\\babel-loader\\lib\\index.js","mtime":1560457563473},{"path":"C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\node_modules\\cache-loader\\dist\\cjs.js","mtime":1560457563834},{"path":"C:\\Users\\My Pc\\Documents\\GitHub\\vue-flask-sqlalchemy\\frontend\\node_modules\\vue-loader\\lib\\index.js","mtime":1560457580480}],"contextDependencies":[],"result":["//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n\r\n// useful tutorial: https://www.youtube.com/watch?v=CVClHLwv-4I&feature=youtu.be\r\n// https://github.com/WebDevSimplified/Face-Detection-JavaScript/blob/master/script.js\r\n\r\nimport * as faceapi from \"face-api.js\";\r\nimport { async } from \"q\";\r\nimport { setTimeout, setInterval } from \"timers\";\r\n\r\nexport default {\r\n  name: \"FaceDetection\",\r\n  components: {},\r\n  data: function() {\r\n    return {\r\n      display_size: { width: 640, height: 480 },\r\n      detections: \"\"\r\n    };\r\n  },\r\n  mounted: function() {\r\n    this.load_models();\r\n    this.call_faceapi();\r\n    this.start_video();\r\n  },\r\n  methods: {\r\n    call_faceapi: function() {\r\n      console.log(faceapi.nets);\r\n    },\r\n\r\n    load_models: function() {\r\n      Promise.all([\r\n        // save the models to the public/models\r\n        // faceapi.nets.ssdMobilenetv1.loadFromUri(\"/models\"),\r\n        faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\"),\r\n        faceapi.nets.faceLandmark68Net.loadFromUri(\"/models\"),\r\n        faceapi.nets.faceRecognitionNet.loadFromUri(\"/models\"),\r\n        faceapi.nets.faceExpressionNet.loadFromUri(\"/models\"),\r\n        faceapi.nets.ageGenderNet.loadFromUri(\"/models\")\r\n      ]);\r\n      console.log(\"done\");\r\n    },\r\n    start_video: function() {\r\n      navigator.getUserMedia(\r\n        { video: {} },\r\n        stream => (video.srcObject = stream),\r\n        err => console.error(err)\r\n      );\r\n    },\r\n    detect_and_draw_faces: function() {\r\n      // https://michaelnthiessen.com/this-is-undefined/\r\n      // https://stackoverflow.com/questions/47148363/when-to-use-vm-or-this-in-vue-js\r\n      // arrow function is a pain in vue.js and this async function also seems to cause problem\r\n      let vm = this;\r\n      setInterval(async function() {\r\n        //   After face detection and facial landmark prediction the face descriptors\r\n        vm.detections = await faceapi\r\n          .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())\r\n          .withFaceLandmarks()\r\n          .withFaceExpressions()\r\n          .withAgeAndGender()\r\n          .withFaceDescriptors()\r\n\r\n        // calculated the size that is on our canvas size\r\n        const resizedDetections = faceapi.resizeResults(\r\n          vm.detections,\r\n          vm.display_size\r\n        );\r\n\r\n        // clear canvas before drawing the new things to prevent cluttering\r\n        vm.$refs.canvas\r\n          .getContext(\"2d\")\r\n          .clearRect(0, 0, vm.$refs.canvas.width, vm.$refs.canvas.height);\r\n\r\n        faceapi.draw.drawDetections(vm.$refs.canvas, resizedDetections);\r\n        faceapi.draw.drawFaceLandmarks(vm.$refs.canvas, resizedDetections);\r\n        faceapi.draw.drawFaceExpressions(vm.$refs.canvas, resizedDetections);\r\n\r\n      }, 500);\r\n    },\r\n    download_face_descriptor: function(){\r\n        console.log(this.detections)\r\n        // specify which person as the algo track all the faces\r\n        console.log(this.detections['0'].descriptor)\r\n        this.axios({\r\n        url: this.$API_URL + \"/face_descriptor\",\r\n        method: \"POST\",\r\n        data: {\r\n          descriptor: this.detections['0'].descriptor\r\n        }\r\n      }).then(response => {});\r\n    }\r\n  }\r\n};\r\n",{"version":3,"sources":["FaceDetection.vue"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;AAsBA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"FaceDetection.vue","sourceRoot":"src/components","sourcesContent":["<template>\r\n  <div>\r\n    <v-container grid-list-md text-xs-center fluid>\r\n      <v-layout align-center justify-center>\r\n        <video\r\n          id=\"video\"\r\n          ref=\"video\"\r\n          :width=\"display_size.width\"\r\n          :height=\"display_size.height\"\r\n          autoplay\r\n          @play=\"detect_and_draw_faces\"\r\n        ></video>\r\n        <canvas id=\"canvas\" ref=\"canvas\" :width=\"display_size.width\" :height=\"display_size.height\"></canvas>\r\n      </v-layout>\r\n      <v-layout align-center justify-center>\r\n          <v-btn @click=\"download_face_descriptor\"> download vector</v-btn>\r\n      </v-layout>      \r\n    </v-container>\r\n  </div>\r\n</template>\r\n\r\n<script>\r\n// useful tutorial: https://www.youtube.com/watch?v=CVClHLwv-4I&feature=youtu.be\r\n// https://github.com/WebDevSimplified/Face-Detection-JavaScript/blob/master/script.js\r\n\r\nimport * as faceapi from \"face-api.js\";\r\nimport { async } from \"q\";\r\nimport { setTimeout, setInterval } from \"timers\";\r\n\r\nexport default {\r\n  name: \"FaceDetection\",\r\n  components: {},\r\n  data: function() {\r\n    return {\r\n      display_size: { width: 640, height: 480 },\r\n      detections: \"\"\r\n    };\r\n  },\r\n  mounted: function() {\r\n    this.load_models();\r\n    this.call_faceapi();\r\n    this.start_video();\r\n  },\r\n  methods: {\r\n    call_faceapi: function() {\r\n      console.log(faceapi.nets);\r\n    },\r\n\r\n    load_models: function() {\r\n      Promise.all([\r\n        // save the models to the public/models\r\n        // faceapi.nets.ssdMobilenetv1.loadFromUri(\"/models\"),\r\n        faceapi.nets.tinyFaceDetector.loadFromUri(\"/models\"),\r\n        faceapi.nets.faceLandmark68Net.loadFromUri(\"/models\"),\r\n        faceapi.nets.faceRecognitionNet.loadFromUri(\"/models\"),\r\n        faceapi.nets.faceExpressionNet.loadFromUri(\"/models\"),\r\n        faceapi.nets.ageGenderNet.loadFromUri(\"/models\")\r\n      ]);\r\n      console.log(\"done\");\r\n    },\r\n    start_video: function() {\r\n      navigator.getUserMedia(\r\n        { video: {} },\r\n        stream => (video.srcObject = stream),\r\n        err => console.error(err)\r\n      );\r\n    },\r\n    detect_and_draw_faces: function() {\r\n      // https://michaelnthiessen.com/this-is-undefined/\r\n      // https://stackoverflow.com/questions/47148363/when-to-use-vm-or-this-in-vue-js\r\n      // arrow function is a pain in vue.js and this async function also seems to cause problem\r\n      let vm = this;\r\n      setInterval(async function() {\r\n        //   After face detection and facial landmark prediction the face descriptors\r\n        vm.detections = await faceapi\r\n          .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())\r\n          .withFaceLandmarks()\r\n          .withFaceExpressions()\r\n          .withAgeAndGender()\r\n          .withFaceDescriptors()\r\n\r\n        // calculated the size that is on our canvas size\r\n        const resizedDetections = faceapi.resizeResults(\r\n          vm.detections,\r\n          vm.display_size\r\n        );\r\n\r\n        // clear canvas before drawing the new things to prevent cluttering\r\n        vm.$refs.canvas\r\n          .getContext(\"2d\")\r\n          .clearRect(0, 0, vm.$refs.canvas.width, vm.$refs.canvas.height);\r\n\r\n        faceapi.draw.drawDetections(vm.$refs.canvas, resizedDetections);\r\n        faceapi.draw.drawFaceLandmarks(vm.$refs.canvas, resizedDetections);\r\n        faceapi.draw.drawFaceExpressions(vm.$refs.canvas, resizedDetections);\r\n\r\n      }, 500);\r\n    },\r\n    download_face_descriptor: function(){\r\n        console.log(this.detections)\r\n        // specify which person as the algo track all the faces\r\n        console.log(this.detections['0'].descriptor)\r\n        this.axios({\r\n        url: this.$API_URL + \"/face_descriptor\",\r\n        method: \"POST\",\r\n        data: {\r\n          descriptor: this.detections['0'].descriptor\r\n        }\r\n      }).then(response => {});\r\n    }\r\n  }\r\n};\r\n</script>\r\n\r\n<style scope>\r\n@import url(\"https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\");\r\n\r\n#video {\r\n  /* position: absolute; */\r\n  z-index: 1;\r\n  pointer-events: none;\r\n}\r\n\r\n#canvas {\r\n  position: absolute;\r\n  z-index: 2;\r\n  pointer-events: none;\r\n}\r\n\r\n.dropzone-custom-title {\r\n  margin-top: 0;\r\n  color: #00b782;\r\n}\r\n\r\n.subtitle {\r\n  color: #314b5f;\r\n}\r\n</style>\r\n"]}]}